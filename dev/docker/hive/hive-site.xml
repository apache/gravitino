<configuration>
  <property>
    <name>hive.server2.enable.doAs</name>
    <value>true</value>
    <description>Disable user impersonation for HiveServer2</description>
  </property>

  <property>
    <name>hive.exec.scratchdir</name>
    <value>/tmp</value>
    <description>Scratch space for Hive jobs</description>
  </property>

  <property>
    <name>mapred.child.java.opts</name>
    <value>-Xmx4G -XX:+UseConcMarkSweepGC</value>
    <description>Max memory for Map Reduce Jobs</description>
  </property>

  <property>
    <name>javax.jdo.option.ConnectionURL</name>
    <value>jdbc:mysql://localhost/metastore_db?createDatabaseIfNotExist=true&amp;useSSL=false</value>
  </property>

  <property>
    <name>javax.jdo.option.ConnectionUserName</name>
    <value>hive</value>
  </property>

  <property>
    <name>javax.jdo.option.ConnectionPassword</name>
    <value>hive</value>
  </property>

  <property>
    <name>javax.jdo.option.ConnectionDriverName</name>
    <value>com.mysql.jdbc.Driver</value>
  </property>

  <property>
    <name>hive.metastore.warehouse.dir</name>
    <value>hdfs://__REPLACE__HOST_NAME:9000/user/hive/warehouse</value>
    <description>location of default database for the warehouse</description>
  </property>

  <property>
    <name>fs.s3a.access.key</name>
    <value>S3_ACCESS_KEY_ID</value>
  </property>

  <property>
    <name>fs.s3a.secret.key</name>
    <value>S3_SECRET_KEY_ID</value>
  </property>

  <property>
    <name>fs.s3a.endpoint</name>
    <value>S3_ENDPOINT_ID</value>
  </property>

  <property>
    <name>fs.s3a.aws.credentials.provider</name>
    <value>org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider,com.amazonaws.auth.EnvironmentVariableCredentialsProvider,org.apache.hadoop.fs.s3a.AnonymousAWSCredentialsProvider</value>
  </property>

</configuration>
