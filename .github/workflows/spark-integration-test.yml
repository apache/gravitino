name: Spark Integration Test

# Controls when the workflow will run
on:
  # Triggers the workflow on push or pull request events but only for the "main" branch
  push:
    branches: [ "main", "branch-*" ]
  pull_request:
    branches: [ "main", "branch-*" ]

concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: true

jobs:
  changes:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: dorny/paths-filter@v2
        id: filter
        with:
          filters: |
            source_changes:
              - .github/**
              - api/**
              - bin/**
              - catalogs/**
              - clients/client-java/**
              - clients/client-java-runtime/**
              - clients/filesystem-hadoop3/**
              - clients/filesystem-hadoop3-runtime/**
              - common/**
              - conf/**
              - core/**
              - dev/**
              - gradle/**
              - meta/**
              - server/**
              - server-common/**
              - spark-connector/**
              - docs/open-api/**
              - build.gradle.kts
              - gradle.properties
              - gradlew
              - setting.gradle.kts
    outputs:
      source_changes: ${{ steps.filter.outputs.source_changes }}

  # Integration test for AMD64 architecture
  test-amd64-arch:
    needs: changes
    if: needs.changes.outputs.source_changes == 'true'
    runs-on: ubuntu-latest
    timeout-minutes: 90
    strategy:
      matrix:
        architecture: [linux/amd64]
        java-version: [ 8, 11, 17 ]
        test-mode: [ embedded, deploy ]
    env:
      PLATFORM: ${{ matrix.architecture }}
    steps:
      - uses: actions/checkout@v3

      - uses: actions/setup-java@v3
        with:
          java-version: ${{ matrix.java-version }}
          distribution: 'temurin'

      - name: Set up QEMU
        uses: docker/setup-qemu-action@v2

      - name: Check required command
        run: |
          dev/ci/check_commands.sh

      - name: Package Gravitino
        if : ${{ matrix.test-mode == 'deploy' }}
        run: |
          ./gradlew compileDistribution -x test -PjdkVersion=${{ matrix.java-version }}

      - name: Setup debug Github Action
        if: ${{ contains(github.event.pull_request.labels.*.name, 'debug action') }}
        uses: csexton/debugger-action@master

      - name: Free up disk space
        run: |
          dev/ci/util_free_space.sh

      - name: Spark Integration Test
        id: integrationTest
        run: |
          ./gradlew --rerun-tasks -PskipTests -PtestMode=${{ matrix.test-mode }} -PjdkVersion=${{ matrix.java-version }} :spark-connector:spark3.3:test --tests "com.datastrato.gravitino.spark.connector.integration.test.**"
          ./gradlew --rerun-tasks -PskipTests -PtestMode=${{ matrix.test-mode }} -PjdkVersion=${{ matrix.java-version }} :spark-connector:spark3.4:test --tests "com.datastrato.gravitino.spark.connector.integration.test.**"
          ./gradlew --rerun-tasks -PskipTests -PtestMode=${{ matrix.test-mode }} -PjdkVersion=${{ matrix.java-version }} :spark-connector:spark3.5:test --tests "com.datastrato.gravitino.spark.connector.integration.test.**"

      - name: Upload integrate tests reports
        uses: actions/upload-artifact@v3
        if: ${{ (failure() && steps.integrationTest.outcome == 'failure') || contains(github.event.pull_request.labels.*.name, 'upload log') }}
        with:
          name: spark-connector-integrate-test-reports-${{ matrix.java-version }}-${{ matrix.test-mode }}
          path: |
            build/reports
            spark-connector/spark3.3/build/spark3.3-integration-test.log
            spark-connector/spark3.4/build/spark3.4-integration-test.log
            spark-connector/spark3.5/build/spark3.5-integration-test.log
            distribution/package/logs/gravitino-server.out
            distribution/package/logs/gravitino-server.log
