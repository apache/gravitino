---
title: "Hadoop catalog with S3"
slug: /hadoop-catalog-with-s3
date: 2025-01-03
keyword: Hadoop catalog S3
license: "This software is licensed under the Apache License version 2."
---

This document explains how to configure a Hadoop catalog with S3 in Gravitino.

## Prerequisites

To create a Hadoop catalog with S3, follow these steps:

1. Download the `gravitino-aws-bundle-${gravitino-version}.jar` file
   the [maven repository](https://mvnrepository.com/artifact/org.apache.gravitino/gravitino-aws-bundle).

1. Place this file in the Gravitino Hadoop catalog class path
   at `${GRAVITINO_HOME}/catalogs/hadoop/libs/`.

1. Start the Gravitino server using the following command:

   ```bash
   ${GRAVITINO_HOME}/bin/gravitino-server.sh start
   ```

Once the server is up and running, you can proceed to configure the Hadoop catalog with S3.
In the rest of this document we will use `http://localhost:8090` as the Gravitino server URL.
Please replace it with your actual server URL.

## Configurations for creating a Hadoop catalog with S3

### Configurations for S3 Hadoop Catalog

In addition to the basic configurations mentioned in
[Hadoop-catalog-catalog-configuration](./hadoop-catalog.md#catalog-properties),
the following properties are necessary to configure a Hadoop catalog with S3:

<table>
<thead>
<tr>
  <th>Configuration item</th>
  <th>Description</th>
  <th>Default value</th>
  <th>Required</th>
  <th>Since version</th>
</tr>
</thead>
<tbody>
<tr>
  <td><tt>filesystem-providers</tt></td>
  <td>
    The file system providers to add.
    Set it to `s3` if it's a S3 fileset, or a comma separated string that contains `s3`
    like `gs,s3` to support multiple kinds of fileset including `s3`.
  </td>
  <td>(none)</td>
  <td>Yes</td>
  <td>`0.7.0-incubating`</td>
</tr>
<tr>
  <td><tt>default-filesystem-provider</tt></td>
  <td>
    The name default filesystem providers of this Hadoop catalog
    if user does not specify the scheme in the URI.
    The default value is `builtin-local` for S3.
    If we set this value, we can omit the prefix 's3a://' in the <tt>location</tt>.
  </td>
  <td>`builtin-local`</td>
  <td>No</td>
  <td>`0.7.0-incubating`</td>
</tr>
<tr>
  <td><tt>s3-endpoint</tt></td>
  <td>The endpoint of the AWS S3.</td>
  <td>(none)</td>
  <td>Yes</td>
  <td>`0.7.0-incubating`</td>
</tr>
<tr>
  <td><tt>s3-access-key-id</tt></td>
  <td>The access key of the AWS S3.</td>
  <td>(none)</td>
  <td>Yes</td>
  <td>`0.7.0-incubating`</td>
</tr>
<tr>
  <td><tt>s3-secret-access-key</tt></td>
  <td>The secret key of the AWS S3.</td>
  <td>(none)</td>
  <td>Yes</td>
  <td>`0.7.0-incubating`</td>
</tr>
<tr>
  <td><tt>credential-providers</tt></td>
  <td>
    The credential provider types, separated by comma.
    Valid values can be `s3-token`, `s3-secret-key`.
    Because the default authentication type is using AKSK as the above,
    this configuration can enable credential vending provided by Gravitino server
    and client will no longer need to provide authentication information
    like AKSK to access S3 by GVFS.
    When this is set, more configuration items are needed to make it works.
    Please see [s3-credential-vending](../../../security/credential-vending.md#s3-credentials)
    for more details.
  </td>
  <td>(none)</td>
  <td>No</td>
  <td>`0.8.0-incubating`</td>
</tr>
</tbody>
</table>

### Configurations for a schema

To learn how to create a schema, refer to [Schema configurations](./hadoop-catalog.md#schema-properties).

### Configurations for a fileset

For more details on creating a fileset, refer to [Fileset configurations](./hadoop-catalog.md#fileset-properties).

## Using the Hadoop catalog with S3

This section demonstrates how to use the Hadoop catalog with S3
in Gravitino, with a complete example.

### Step1: Create a Hadoop Catalog with S3

First of all, you need to create a Hadoop catalog with S3.
The following example shows how to create a Hadoop catalog with S3:

<Tabs groupId="language" queryString>
<TabItem value="shell" label="Shell">

```shell
cat <<EOF >catalog.json
{
  "name": "mycatalog",
  "type": "FILESET",
  "comment": "This is a S3 fileset catalog",
  "provider": "hadoop",
  "properties": {
    "location": "s3a://bucket/root",
    "s3-access-key-id": "access_key",
    "s3-secret-access-key": "secret_key",
    "s3-endpoint": "http://s3.ap-northeast-1.amazonaws.com",
    "filesystem-providers": "s3"
  }
}
EOF

curl -X POST \
  -H "Accept: application/vnd.gravitino.v1+json" \
  -H "Content-Type: application/json" \
  -d '@catalog.json' \
  http://localhost:8090/api/metalakes/mymetalake/catalogs
```

</TabItem>
<TabItem value="java" label="Java">

```java
GravitinoClient gravitinoClient = GravitinoClient
    .builder("http://localhost:8090")
    .withMetalake("mymetalake")
    .build();

Map<String, String> s3Properties = ImmutableMap.<String, String>builder()
    .put("location", "s3a://bucket/root")
    .put("s3-access-key-id", "access_key")
    .put("s3-secret-access-key", "secret_key")
    .put("s3-endpoint", "http://s3.ap-northeast-1.amazonaws.com")
    .put("filesystem-providers", "s3")
    .build();

Catalog s3Catalog = gravitinoClient.createCatalog(
    "mycatalog",
    Type.FILESET,
    "hadoop", // provider, Gravitino only supports "hadoop" for now.
    "This is a S3 fileset catalog",
    s3Properties);
```

</TabItem>
<TabItem value="python" label="Python">

```python
client = GravitinoClient(uri="http://localhost:8090",
                         metalake_name="mymetalake")
s3_properties = {
    "location": "s3a://bucket/root",
    "s3-access-key-id": "access_key"
    "s3-secret-access-key": "secret_key",
    "s3-endpoint": "http://s3.ap-northeast-1.amazonaws.com",
    "filesystem-providers": "s3"
}

s3_catalog = client.create_catalog(
    name="mycatalog",
    catalog_type=Catalog.Type.FILESET,
    provider="hadoop",
    comment="This is a S3 fileset catalog",
    properties=s3_properties)
```
</TabItem>
</Tabs>

:::note
When using S3 with Hadoop, ensure that the location value starts with `s3a://` (not `s3://`) for AWS S3.
For example, use `s3a://bucket/root`, as the `s3://` format is not supported by the 'hadoop-aws' library.
:::

### Step2: Create a schema

Once your Hadoop catalog with S3 is created, you can create a schema under the catalog.
Here are examples of how to do that:

<Tabs groupId="language" queryString>
<TabItem value="shell" label="Shell">

```shell
cat <<EOF >schema.json
{
  "name": "myschema",
  "comment": "This is a S3 schema",\
  "properties": {
    "location": "s3a://bucket/root/schema"
  }
}
EOF

curl -X POST \
  -H "Accept: application/vnd.gravitino.v1+json" \
  -H "Content-Type: application/json" \
  -d '@schema.json' \
  http://localhost:8090/api/metalakes/mymetalake/catalogs/mycatalog/schemas
```
</TabItem>
<TabItem value="java" label="Java">

```java
Catalog catalog = gravitinoClient.loadCatalog("mycatalog");

SupportsSchemas supportsSchemas = catalog.asSchemas();

Map<String, String> schemaProperties = ImmutableMap.<String, String>builder()
    .put("location", "s3a://bucket/root/schema")
    .build();
Schema schema = supportsSchemas.createSchema("myschema",
    "This is a S3 schema",
    schemaProperties
);
```

</TabItem>
<TabItem value="python" label="Python">

```python
client = GravitinoClient(uri="http://localhost:8090",
                         metalake_name="mymetalake")
catalog = client.load_catalog(name="mycatalog")
catalog.as_schemas().create_schema(
    name="myschema",
    comment="This is a S3 schema",
    properties={"location": "s3a://bucket/root/schema"})
```
</TabItem>
</Tabs>

### Step3: Create a fileset

After creating the schema, you can create a fileset.
Here are examples for creating a fileset:

<Tabs groupId="language" queryString>
<TabItem value="shell" label="Shell">

```shell
cat <<EOF >fileset.json
{
  "name": "myfileset",
  "comment": "This is an example fileset",
  "type": "MANAGED",
  "storageLocation": "s3a://bucket/root/schema/example_fileset",
  "properties": {
    "k1": "v1"
  }
}
EOF

curl -X POST \
  -H "Accept: application/vnd.gravitino.v1+json" \
  -H "Content-Type: application/json" \
  -d '@fileset.json' \
  http://localhost:8090/api/metalakes/mymetalake/catalogs/mycatalog/schemas/myschema/filesets
```

</TabItem>
<TabItem value="java" label="Java">

```java
GravitinoClient gravitinoClient = GravitinoClient
    .builder("http://localhost:8090")
    .withMetalake("mymetalake")
    .build();

Catalog catalog = gravitinoClient.loadCatalog("mycatalog");
FilesetCatalog filesetCatalog = catalog.asFilesetCatalog();

Map<String, String> propertiesMap = ImmutableMap.<String, String>builder()
      .put("k1", "v1")
      .build();

filesetCatalog.createFileset(
    NameIdentifier.of("myschema", "myfileset"),
    "This is an example fileset",
    Fileset.Type.MANAGED,
    "s3a://bucket/root/schema/example_fileset",
    propertiesMap,
);
```

</TabItem>
<TabItem value="python" label="Python">

```python
client = GravitinoClient(uri="http://localhost:8090",
                         metalake_name="mymetalake")
catalog = client.load_catalog(name="mycatalog")
catalog.as_fileset_catalog().create_fileset(
  ident=NameIdentifier.of("myschema", "myfileset"),
  type=Fileset.Type.MANAGED,
  comment="This is an example fileset",
  storage_location="s3a://bucket/root/schema/example_fileset",
  properties={"k1": "v1"}
)
```

</TabItem>
</Tabs>

## Accessing a fileset with S3

### Using the GVFS Java client to access the fileset

To access fileset with S3 using the GVFS Java client, 
based on the [basic GVFS configurations](../gvfs/index.md#java-gvfs-configuration),
you need to add the following configurations:

<table>
<thead>
<tr>
  <th>Configuration item</th>
  <th>Description</th>
  <th>Default value</th>
  <th>Required</th>
  <th>Since version</th>
</tr>
</thead>
<tbody>
<tr>
  <td><tt>s3-endpoint</tt></td>
  <td>The endpoint of the AWS S3.</td>
  <td>(none)</td>
  <td>Yes</td>
  <td>`0.7.0-incubating`</td>
</tr>
<tr>
  <td><tt>s3-access-key-id</tt></td>
  <td>The access key of the AWS S3.</td>
  <td>(none)</td>
  <td>Yes</td>
  <td>`0.7.0-incubating`</td>
</tr>
<tr>
  <td><tt>s3-secret-access-key</tt></td>
  <td>The secret key of the AWS S3.</td>
  <td>(none)</td>
  <td>Yes</td>
  <td>`0.7.0-incubating`</td>
</tr>
</tbody>
</table>

:::note
If the catalog has enabled [credential vending](../../../security/credential-vending.md),
the properties above can be omitted.
More details can be found in [Fileset with credential vending](#fileset-with-credential-vending).
:::

```java
Configuration conf = new Configuration();
conf.set("fs.AbstractFileSystem.gvfs.impl", "org.apache.gravitino.filesystem.hadoop.Gvfs");
conf.set("fs.gvfs.impl", "org.apache.gravitino.filesystem.hadoop.GravitinoVirtualFileSystem");
conf.set("fs.gravitino.server.uri", "http://localhost:8090");
conf.set("fs.gravitino.client.metalake", "mymetalake");
conf.set("s3-endpoint", "http://localhost:8090");
conf.set("s3-access-key-id", "minio");
conf.set("s3-secret-access-key", "minio123");

Path filesetPath = new Path("gvfs://fileset/mycatalog/myschema/myfileset/new_dir");
FileSystem fs = filesetPath.getFileSystem(conf);
fs.mkdirs(filesetPath);
...
```

Similar to Spark configurations, you need to add S3 (bundle) JARs
to the class path in your environment.

```xml
  <dependency>
    <groupId>org.apache.hadoop</groupId>
    <artifactId>hadoop-common</artifactId>
    <version>${HADOOP_VERSION}</version>
  </dependency>

  <dependency>
    <groupId>org.apache.hadoop</groupId>
    <artifactId>hadoop-aws</artifactId>
    <version>${HADOOP_VERSION}</version>
  </dependency>

  <dependency>
    <groupId>org.apache.gravitino</groupId>
    <artifactId>filesystem-hadoop3-runtime</artifactId>
    <version>${GRAVITINO_VERSION}</version>
  </dependency>

  <dependency>
    <groupId>org.apache.gravitino</groupId>
    <artifactId>gravitino-aws</artifactId>
    <version>${GRAVITINO_VERSION}</version>
  </dependency>
```

Or you can use the bundle JAR with Hadoop environment
if there is no Hadoop environment:

```xml
<dependency>
  <groupId>org.apache.gravitino</groupId>
  <artifactId>gravitino-aws-bundle</artifactId>
  <version>${GRAVITINO_VERSION}</version>
</dependency>

<dependency>
  <groupId>org.apache.gravitino</groupId>
  <artifactId>filesystem-hadoop3-runtime</artifactId>
  <version>${GRAVITINO_VERSION}</version>
</dependency>
```

### Using Spark to access the fileset

The following Python code demonstrates how to use
**PySpark 3.1.3 with Hadoop environment(Hadoop 3.2.0)** to access the fileset:

Before running the following code, you need to install required packages:

```bash
pip install pyspark==3.1.3
pip install apache-gravitino==${GRAVITINO_VERSION}
```
Then you can run the following code:

```python
from pyspark.sql import SparkSession
import os

gravitino_url = "http://localhost:8090"
metalake_name = "mymetalake"

catalog_name = "your_s3_catalog"
schema_name = "your_s3_schema"
fileset_name = "your_s3_fileset"
jars = ".".join([
  /path/to/gravitino-aws-${gravitino-version}.jar",
  "/path/to/gravitino-filesystem-hadoop3-runtime-${gravitino-version}-SNAPSHOT.jar",
  "/path/to/hadoop-aws-3.2.0.jar,",
  "/path/to/aws-java-sdk-bundle-1.11.375.jar",
])

os.environ["PYSPARK_SUBMIT_ARGS"] = "--jars " + jars + " --master local[1] pyspark-shell"

spark = SparkSession.builder
    .appName("s3_fileset_test")
    .config("spark.hadoop.fs.AbstractFileSystem.gvfs.impl", "org.apache.gravitino.filesystem.hadoop.Gvfs")
    .config("spark.hadoop.fs.gvfs.impl", "org.apache.gravitino.filesystem.hadoop.GravitinoVirtualFileSystem")
    .config("spark.hadoop.fs.gravitino.server.uri", "http://localhost:8090")
    .config("spark.hadoop.fs.gravitino.client.metalake", "mymetalake")
    .config("spark.hadoop.s3-access-key-id", os.environ["S3_ACCESS_KEY_ID"])
    .config("spark.hadoop.s3-secret-access-key", os.environ["S3_SECRET_ACCESS_KEY"])
    .config("spark.hadoop.s3-endpoint", "http://s3.ap-northeast-1.amazonaws.com")
    .config("spark.driver.memory", "2g")
    .config("spark.driver.port", "2048")
    .getOrCreate()

data = [("Alice", 25), ("Bob", 30), ("Cathy", 45)]
columns = ["Name", "Age"]
spark_df = spark.createDataFrame(data, schema=columns)
gvfs_path = f"gvfs://fileset/{catalog}/{schema}/{fileset}/people"

spark_df.coalesce(1).write
    .mode("overwrite")
    .option("header", "true")
    .csv(gvfs_path)
```

If **don't have Hadoop environment** for your Spark deployment,
you can use the following code snippet to access the fileset:
    
```python
jars = ".".join([
  "/path/to/gravitino-aws-bundle-${gravitino-version}.jar",
  "/path/to/gravitino-filesystem-hadoop3-runtime-${gravitino-version}-SNAPSHOT.jar"
])
os.environ["PYSPARK_SUBMIT_ARGS"] = "--jars " + jars + " --master local[1] pyspark-shell"
```

- The `gravitino-aws-bundle-${gravitino-version}.jar` JAR file 
  the Gravitino AWS JAR with Hadoop environment (3.3.1)
  and it includes `hadoop-aws` jar.
  You can get it from the [maven repository](https://mvnrepository.com/artifact/org.apache.gravitino/gravitino-aws-bundle).

- The `gravitino-aws-${gravitino-version}.jar` is a condensed version
  of the Gravitino AWS bundle JAR without Hadoop environment or the `hadoop-aws` JAR.
  This JAR is available at the [maven repository](https://mvnrepository.com/artifact/org.apache.gravitino/gravitino-aws).

- `hadoop-aws-3.2.0.jar` and `aws-java-sdk-bundle-1.11.375.jar` can be found in the Hadoop distribution
  in the `${HADOOP_HOME}/share/hadoop/tools/lib` directory. 

Please choose the correct jar according to your environment.

:::note
For some Spark versions, a Hadoop environment is needed by the driver,
adding the bundle JARs with '--jars' may not work.
If this is the case, you should add the JARs to the Spark class path directly.
:::

### Accessing a fileset using the Hadoop fs command

The following are examples of how to use the `hadoop fs` command
to access the fileset in Hadoop 3.1.3.

1. Adding the following contents to the `${HADOOP_HOME}/etc/hadoop/core-site.xml` file:

   ```xml
   <property>
     <name>fs.AbstractFileSystem.gvfs.impl</name>
     <value>org.apache.gravitino.filesystem.hadoop.Gvfs</value>
   </property>
 
   <property>
     <name>fs.gvfs.impl</name>
     <value>org.apache.gravitino.filesystem.hadoop.GravitinoVirtualFileSystem</value>
   </property>
 
   <property>
     <name>fs.gravitino.server.uri</name>
     <value>http://localhost:8090</value>
   </property>
 
   <property>
     <name>fs.gravitino.client.metalake</name>
     <value>test</value>
   </property>
 
   <property>
     <name>s3-endpoint</name>
     <value>http://s3.ap-northeast-1.amazonaws.com</value>
   </property>
 
   <property>
     <name>s3-access-key-id</name>
     <value>access-key</value>
   </property>
   
   <property>
   <name>s3-secret-access-key</name>
     <value>secret-key</value>
   </property>
   ```

1. Add the necessary jars to the Hadoop classpath. 

   For S3, you need to add `gravitino-filesystem-hadoop3-runtime-${gravitino-version}.jar`,
   `gravitino-aws-${gravitino-version}.jar` and `hadoop-aws-${hadoop-version}.jar`
   located at `${HADOOP_HOME}/share/hadoop/tools/lib/` to Hadoop classpath. 

1. Run the following command to access the fileset:

   ```shell
   ./${HADOOP_HOME}/bin/hadoop dfs -ls gvfs://fileset/s3_catalog/s3_schema/s3_fileset
   ./${HADOOP_HOME}/bin/hadoop dfs -put /path/to/local/file gvfs://fileset/s3_catalog/s3_schema/s3_fileset
   ```

### Using the GVFS Python client to access a fileset

In order to access fileset with S3 using the GVFS Python client,
apart from [basic GVFS configurations](../gvfs/index.md#python-gvfs-configuration),
you need to add the following configurations:

<table>
<thead>
<tr>
  <th>Configuration item</th>
  <th>Description</th>
  <th>Default value</th>
  <th>Required</th>
  <th>Since version</th>
</tr>
</thead>
<tbody>
<tr>
  <td><tt>s3_endpoint</tt></td>
  <td>
    The endpoint of the AWS S3.
    This configuration is optional for S3 service, but required
    for other S3-compatible storage services like MinIO.
  </td>
  <td>(none)</td>
  <td>No</td>
  <td>`0.7.0-incubating`</td>
</tr>
<tr>
  <td><tt>s3_access_key_id</tt></td>
  <td>The access key of the AWS S3.</td>
  <td>(none)</td>
  <td>Yes</td>
  <td>`0.7.0-incubating`</td>
</tr>
<tr>
  <td><tt>s3_secret_access_key</tt></td>
  <td>The secret key of the AWS S3.</td>
  <td>(none)</td>
  <td>Yes</td>
  <td>`0.7.0-incubating`</td>
</tr>
</tbody>
</table>

:::note
- `s3_endpoint` is an optional configuration for GVFS **Python** client
  but a required configuration for GVFS **Java** client to access Hadoop with AWS S3.
  It is required for other S3-compatible storage services like MinIO.

- If the catalog has enabled [credential vending](../../../security/credential-vending.md),
  the properties above can be omitted.
:::

Please install the `gravitino` package before running the following code:

```bash
pip install apache-gravitino==${GRAVITINO_VERSION}
```

```python
from gravitino import gvfs
options = {
    "cache_size": 20,
    "cache_expired_time": 3600,
    "auth_type": "simple",
    "s3_endpoint": "http://localhost:8090",
    "s3_access_key_id": "minio",
    "s3_secret_access_key": "minio123"
}
fs = gvfs.GravitinoVirtualFileSystem(
    server_uri="http://localhost:8090",
    metalake_name="mymetalake",
    options=options)
fs.ls("gvfs://fileset/{catalog}/{schema}/{fileset}/")
```

### Using fileset with pandas

The following are examples of how to use the 'pandas' library
to access the S3 fileset

```python
import pandas as pd

storage_options = {
    "server_uri": "http://localhost:8090", 
    "metalake_name": "mymetalake",
    "options": {
        "s3_access_key_id": "access_key",
        "s3_secret_access_key": "secret_key",
        "s3_endpoint": "http://s3.ap-northeast-1.amazonaws.com"
    }
}
ds = pd.read_csv("gvfs://fileset/{catalog}/{schema}/{fileset}/people/part-513d.csv",
                 storage_options=storage_options)
ds.head()
```

For more use cases, please refer to the [Gravitino Virtual File System](../gvfs/index.md) document.

## Fileset with credential vending

Starting from *0.8.0-incubating*, Gravitino supports credential vending for S3 fileset.
If the catalog has been [configured with credential](../../../security/credential-vending.md),
you can access S3 fileset without providing authentication information
like `s3-access-key-id` and `s3-secret-access-key` in the properties.

### How to create a S3 Hadoop catalog with credential vending

Apart from configuration method in [create-s3-hadoop-catalog](#configurations-for-s3-hadoop-catalog),
properties needed by [s3-credential](../../../security/credential-vending.md#s3-credentials)
should also be set to enable credential vending for S3 fileset.
Take `s3-token` credential provider for example:

```shell
cat <<EOF > s3-catalog.json
{
  "name": "s3-catalog-with-token",
  "type": "FILESET",
  "comment": "This is a S3 fileset catalog",
  "provider": "hadoop",
  "properties": {
    "location": "s3a://bucket/root",
    "s3-access-key-id": "access_key",
    "s3-secret-access-key": "secret_key",
    "s3-endpoint": "http://s3.ap-northeast-1.amazonaws.com",
    "filesystem-providers": "s3",
    "credential-providers": "s3-token",
    "s3-region":"ap-northeast-1",
    "s3-role-arn":"The ARN of the role to access the S3 data"
  }
}
EOF

curl -X POST \
  -H "Accept: application/vnd.gravitino.v1+json" \
  -H "Content-Type: application/json" \
  -d '@s3-catalog.json' \
  http://localhost:8090/api/metalakes/metalake/catalogs
```

### How to access S3 fileset with credential vending

When the catalog is configured with credentials and client-side credential vending is enabled,
you can access S3 filesets directly using the GVFS Java/Python client or Spark
without providing authentication details.

GVFS Java client:

```java
Configuration conf = new Configuration();
conf.setBoolean("fs.gravitino.enableCredentialVending", true);
conf.set("fs.AbstractFileSystem.gvfs.impl", "org.apache.gravitino.filesystem.hadoop.Gvfs");
conf.set("fs.gvfs.impl", "org.apache.gravitino.filesystem.hadoop.GravitinoVirtualFileSystem");
conf.set("fs.gravitino.server.uri", "http://localhost:8090");
conf.set("fs.gravitino.client.metalake", "mymetalake");
// No need to set s3-access-key-id and s3-secret-access-key
Path filesetPath = new Path("gvfs://fileset/mycatalog/myschema/myfileset/new_dir");
FileSystem fs = filesetPath.getFileSystem(conf);
fs.mkdirs(filesetPath);
```

Spark:

```python
spark = SparkSession.builder
    .appName("s3_fileset_test")
    .config("spark.hadoop.fs.gravitino.enableCredentialVending", "true")
    .config("spark.hadoop.fs.AbstractFileSystem.gvfs.impl", "org.apache.gravitino.filesystem.hadoop.Gvfs")
    .config("spark.hadoop.fs.gvfs.impl", "org.apache.gravitino.filesystem.hadoop.GravitinoVirtualFileSystem")
    .config("spark.hadoop.fs.gravitino.server.uri", "http://localhost:8090")
    .config("spark.hadoop.fs.gravitino.client.metalake", "mymetalake")
    # No need to set s3-access-key-id and s3-secret-access-key
    .config("spark.driver.memory", "2g")
    .config("spark.driver.port", "2048")
    .getOrCreate()
```

Python client and Hadoop command are similar to the above examples.

